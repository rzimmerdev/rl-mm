,Index,author/editor,Title,Data,StateSpace,ActionSpace,Rewards,Algorithm,MultiAgent,ModelFree,Metrics,Benchmark
0,2306.17179,Jiafa He and Cong Zheng and Can Yang,Integrating Tick-level Data and Periodical Signal for High-frequency Market Making,"Simulated,Historical,Real Time","Bid-Ask Spreads,Order Status,Inventory",Bid-Ask Levels,"Running PnL,Inventory Penalty","DQN,PPO",Yes (Dueling),Yes,Returns,No Benchmark
1,2209.07823,Joseph Jerome and Leandro Sanchez-Betancourt and Rahul Savani and Martin Herdegen,Model-based gym environments for limit order book trading,Simulated,Bid-Ask Spreads,Bid-ask Levels,"Running PnL,Inventory Penalty,CARA",N/A,No,Yes,Returns,"Rule-Based,Avellaneda Stoikov"
2,1812.10252,Yagna Patel,Optimizing Market Making using Multi-Agent Reinforcement Learning,Simulated (Agent-Based),"Midprice, Volatility, Volume, Bid-Ask Spreads",Buy-Sell-Hold signals,PnL,"DQN","Yes (Dueling), Yes (Market Agents)",Yes,Returns,"Rule Based,Long-Only"
3,1810.04383,Philippe Bergault and David Evangelista and Olivier Guéant and Douglas Vieira,Closed-form approximations in multi-asset market making,Non-Data,Bid-Ask Spreads,Bid-Ask Spread,PnL,Closed-Form Expression,No,No,Returns,No Benchmark
4,1804.04216,Thomas Spooner and John Fearnley and Rahul Savani and Andreas Koukorinis,Market Making via Reinforcement Learning,Historical,"Inventory, Volatility, Volume, Order Imbalance, Bid-Ask Spreads",Bid-Ask Levels,"Running PnL, Inventory Penalty","Q-Learning, SARSA",No,Yes,"Returns, StdDev",Rule-Based
5,WOS:000718533100001,"Gasperov, Bruno and Begusic, Stjepan and Posedel Simovic, Petra and Kostanjcar, Zvonko",Reinforcement Learning Approaches to Optimal Market Making,,,,,,,,,
6,WOS:000645037600001,"Gasperov, Bruno and Kostanjcar, Zvonko",Market Making With Signals Through Deep Reinforcement Learning,Historical,"Inventory, Price Prediction, Bid-Ask Spreads",Bid-Ask Spreads,"Running PnL, Inventory Penalty",Value-based,Yes (Dueling),Yes,"Returns,Maximum Drawdown,Position","Rule Based,DQN"
7,WOS:000747190900001,"Sun, Tianyuan and Huang, Dechun and Yu, Jie",Market Making Strategy Optimization via Deep Reinforcement Learning,Historical,"Inventory,Order Status,Bid-Ask Spreads",Bid-Ask Spreads,Adverse Cross-Spread,DQN,No,Yes,"Returns,Sharpe","DQN"
8,WOS:000764196704097,"Bessiere, C",Robust Market Making via Adversarial Reinforcement Learning,Simulated (Fitted),Inventory,Bid-Ask Spreads,"PnL,CARA",Closed-Form Expression,No,No,"Returns,Sharpe,Position","Rule-Based,Random"
9,WOS:000955980900001,"Baldacci, Bastien and Manziuk, Iuliia and Mastrolia, Thibaut and Rosenbaum, Mathieu",Market Making and Incentives Design in the Presence of a Dark Pool: A Stackelberg Actor-Critic Approach,,,,,,,,,
10,WOS:000925796700004,"Falces Marin, Javier and Pardo de Vera, David Diaz and Lopez Gonzalo, Eduardo",A reinforcement learning approach to improve the performance of the Avellaneda-Stoikov market-making algorithm,Historical,"Bid-Ask Spreads,Midprice,Order Imbalance,Volatility,Inventory",Bid-Ask Spreads,"PnL,Inventory Penalty","DQN, Genetic Algorithm",Yes (Dueling),Yes,"Sharpe,Maximum Drawdown,Position",DQN
11,WOS:000903090100001,"Barzykin, Alexander and Bergault, Philippe and Gueant, Olivier",Algorithmic market making in dealer markets with hedging and market impact,Historical,"Inventory,Midprice",Bid-ask spread,PnL,Closed-Form Expression,No,No,Returns,None
12,WOS:000945933100051,ACM,Deep Q-Learning Market Makers in a Multi-Agent Simulated Stock Market,Simulated (Agent-Based),"Volume,Inventory,Midprice,Bid-Ask Spreads,",Bid-Ask Spread,Running PnL,DQN,Yes,Yes,Returns,"Rule-Based,DQN,Random"
13,WOS:000526474000001,"Abergel, Frederic and Hure, Come and Huyen Pham",Algorithmic trading in a microstructural limit order book model,Simulated,"Inventory,Bid-Ask Spreads,Order Status",Bid-Ask Spreads,"PnL,CARA,Inventory Penalty",Closed-Form Expression,No,No,Returns,Rule-Based
14,WOS:000613392200007,"Lipton, Alexander and De Prado, Marcos Lopez",A CLOSED-FORM SOLUTION FOR OPTIMAL ORNSTEIN-UHLENBECK DRIVEN TRADING STRATEGIES,Simulated,Bid-Ask Spreads,Bid-Ask Spread,PnL,Closed-Form Expression,No,No,Sharpe,Monte Carlo Estimation
15,Kaelbling1996,L. P. Kaelbling and M. L. Littman and A. W. Moore,Reinforcement Learning: A Survey,,,,,,,,,
16,Ganesh2019,Sumitra Ganesh and Nelson Vadori and Mengda Xu and Hua Zheng and Prashant Reddy and Manuela Veloso,Reinforcement Learning for Market Making in a Multi-agent Dealer Market,Simulated (Agent-Based),"Bid-Ask Spreads,Inventory",Bid-Ask Spreads,"PnL,Inventory Penalty",PPO,Yes,Yes,Returns,DQN
17,Gueant2017,Olivier Guéant,Optimal market making,Historical,Bid-Ask Spreads,Bid-Ask Spreads,"Running PnL,CARA,Inventory Penalty",Closed-Form Expression,No,No,N/A,N/A
18,Avellaneda2008,Marco Avellaneda and Sasha Stoikov,High-frequency trading in a limit order book,Historical,"Inventory,Midprice",Bid-ask spread,PnL,Closed-Form Expression,No,No,Returns,None
19,selser2021optimal,Matias Selser and Javier Kreiner and Manuel Maurette,Optimal Market Making by Reinforcement Learning,Simulated,"Midprice,Inventory,Time",Bid-Ask Spreads,PnL,"DQN,Q-Learning",No,No,"Returns,StdDev,Sharpe",Monte Carlo Estimation
20,bakshaev2020marketmaking,Alexey Bakshaev,Market-making with reinforcement-learning (SAC),Simulated,Midprice,"Bid-Ask Spreads,Inventory",Running PnL,SAC,No,Yes,Sharpe,N/A
21,10.1145/3384441.3395986,"Byrd, David and Hybinette, Maria and Balch, Tucker Hybinette",ABIDES: Towards High-Fidelity Multi-Agent Market Simulation,,,,,,,,,
22,jericevich2021simulation,Ivan Jericevich and Patrick Chang and Tim Gebbie,Simulation and estimation of an agent-based market-model with a matching engine,Simulated (Agent-Based),"Bid-Ask Spreads,Order Imbalance",Bid-Ask Spreads,Running PnL,Closed-Form Expression,Yes,No,Returns,N/A
