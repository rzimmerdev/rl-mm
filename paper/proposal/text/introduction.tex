Há um crescente foco na literatura da computação financeira para com estratégias intra-diárias de \textit{Market Making} \citep{WOS:000963297000001} \citep{Gueant2017} \citep{selser2021optimal} \citep{Ganesh2019}, \citep{WOS:000747190900001}, \citep{WOS:000718533100001}, que consistem em criar ordens de limite buscando lucrar em cima da diferença entre o preço de bid (Melhor preço de compra) e o preço de ask (Melhor preço de venda), cuja diferença é chamada de Bid-Ask-Spread (\textit{BAS}). Por serem estratégias intra-diárias, utilizam técnicas de gerenciamento de risco estritamente voltadas para os horários em que o mercado está aberto e permite a criação de novas ordens. Durante esses horários, um agente de \textit{market-making} (\textit{MM}) pode ofertar simultaneamente ordens limite de compra e venda, sob o risco de poder não ter uma ordem executada até o período de fechamento do mercado \citep{Gueant2012} \citep{selser2021optimal} \citep{bakshaev2020marketmaking}.

Se o agente não tem suas ordens finalizadas, ou escolhe manter um inventário após o fechamento do pregão, estará se sujeitando ao risco associado à posição durante a noite, chamado também de risco noturno, ou \textit{overnight} \citep{Gueant2012}. Esse tipo de risco advém do fato de que o mercado não processa nenhuma ordem existente durante a noite até sua abertura no próximo dia. Logo, qualquer posição \textit{overnight} está vulnerável a eventos inesperados durante esse período, como notícias financeiras, mudanças macroeconômicas e outros que possam resultar em aberturas de mercado voláteis potencialmente desfavoráveis à posição mantida. Um agente capaz de \textbf{maximizar o retorno das operações diárias} e \textbf{minimizar o risco associado à posição noturna} seria portanto uma contribuição crítica para estratégias de \textit{MM} existentes usadas por fundos de investimento, corretoras e bancos.

Com o objetivo de obter uma política de criação de ofertas condicionada a minimizar o risco \textit{overnight} teremos como primeiro desafio determinar uma metodologia para obter dados financeiros e validar nossas hipóteses sobre o ambiente de simulação. É necessário ter em mente que as ordens criadas geram mudanças no estado do mercado e conseguintemente alteram a amostra histórica \citep{WOS:000903090100001}. Uma amostragem não estática impede o uso de técnicas para \textit{backtesting} regulares, pois um agente de MM não é um consumidor de preços (\textit{price-taker} em inglês), mas sim um fornecedor de preços (\textit{price-maker}). Em um cenário real, não é ideal desconsiderar o impacto das interações do agente com o mercado: um agente de \textit{MM} que esteja atuando no mercado tentará sempre manter suas ofertas no melhor patamar de preço possível, de modo a ter suas ordens executadas primeiro. Assim, o envio de novas ofertas afetará as ordens subsequentes deste outro agente, o que define um problema de sistema dinâmico \citep{Gueant2017}. Para tais problemas, serão utilizadas técnicas de controle ótimo de modo a modelar o agente (política de controle), assim como o ambiente (que mais a frente será definido em termos de um Processo de Recompensas de Markov) \citep{Gasperov2021}.

Outro detalhe importante sobre o ambiente é a frequência dos processos de chegada das ordens. Uma nova oferta que ultrapasse o melhor preço do disponível no mercado causa quase de imediato (a depender da corretora) a atualização do livro de ordens. O tempo de chegada irá afetar muito mais a política da estratégia ótima obtida quando comparado com dados usados para estratégias de longo prazo ou de \textit{price-taking} \citep{2306.17179}.

Em suma, tem-se duas etapas adicionais a serem consideradas em conjunto do problema principal de conceitualizar e treinar um agente: 
\begin{itemize}
    \item uso de dados históricos \underline{estáticos} para parametrizar a simulação de um ambiente dinâmico;
    \item considerar a frequência dos dados,  que afetará a política obtida;
\end{itemize}

Como conclusão da pesquisa, esperamos realizar uma modelagem do sistema como um problema de controle e obter uma solução ótima aproximada do sistema usando técnicas de aprenzidado por reforço (especificamente com os algoritmos Q-Learning, possivelmente \textit{Deep Q-Learning} ou pelo método \textit{Actor-Critic}). Tendo obtido a solução ótima, utilizar o agente referente de \textit{MM} que maximize o valor esperado do retorno diário em múltiplos ativos e que se adapte aos processos estocásticos de chegada de ofertas e transações. Como contribuição principal da pesquisa, será modelada a restrição de um risco noturno máximo associado ao inventário do agente ao final do pregão e por fim realizar uma análise comparativa da performance do agente com modelos 'Estado da Arte' já existentes.
